---
node: Research Note Workflows
author: donblair
created_at: 2014-08-12 19:53:01 +0000
timestamp: 1407873181
nid: 11035
cid: 9944
uid: 43651
---



[donblair](../profile/donblair) replying to: [Research Note Workflows](../notes/donblair/08-11-2014/research-note-workflows)

----
Very well put, [@mathew](/profile/mathew) and [@warren](/profile/warren)!  It's so important that we make sure, when doing research that in some cases will involve a very technical and involved procedure, not to fall into a  "let me teach y'all how to do science!" approach, but rather that we work hard to develop modes of doing science that are fully collaborative and participatory.  

I'd also like to put a 'context wrapper' on the ideas that we were proposing in the above note -- I know it's onerous at this point (the discussion here has really blossomed!) -- but I think it's important to read the entire post, watch the video, and read the entire comment thread above in order to understand the context for the ideas that Jeff Walker and I were floating here.

But, as a quick short cut, here's what I think is a useful analogy:  the kind of data analysis workflow that Jeff Walker is experimenting with right now in analyzing water quality data is, perhaps, as technically involved (and yet amenable to automation) as the workflow that is required to e.g. analyze Public Lab's spectral data or infragram data -- if you include the software development around spectralworkbench.org and infrgram.org as part of that workflow.  Developing, tweaking, version controlling, and commenting on this water quality data analysis workflow (which involves using R, a software system with several powerful, but not necessarily user-friendly software packages) seems like a great fit for github, in the same way that e.g. spectralworkbench.org development is best done there.  In particular, JDW and I have envisioned setting up an "executable document" of the sort that RStudio can generate -- a combination of problem statement, data, and executable analysis code -- so that not only is the entire analysis in one place, but folks who want to repeat the analysis can simply 'fork' this document, plug in their own dataset, and repeat the same analysis themselves.

Accordingly,

>  If publishing is limited to only those folks who know how to use Github, aren't we missing out on key insights from a broad swath of potential collaborators?

Yes -- great point -- this is a huge problem! And I'd say that this is also true for e.g. spectralworkbench.org development, in much the same way. Collaborating with the publiclab.org community on spectralworkbench.org development right now is heavily biased against people who don't know how to use github; by choosing to develop this tool on the github platform, we're alienating a lot of people who are highly motivated to contribute to the project -- ranging from people who are simply concerned about their tap water, to a lot of talented coders and chemists who possess complementary expertise.  

What we're trying to figure out here is:  how can we aim for the kind of collaborative, fully participatory, peer-to-peer science and technology development we want -- which sometimes is as technically demanding as the coding required for spectralworkbench.org -- and make collaboration and participation as accessible as possible for as many people as possible?  What I think JDW has come up with above, in the context of analyzing water quality data, is sort of the equivalent, for spectralworkbench, of a workflow that would regularly post a publiclab.org research summary note about the latest spectralworkbench update ... and the research note would also link to an in-depth, self-contained document, on github, that leads any developer through the process of setting up, running, and adding features to spectralworkbench.org on their home computer.  

Hope the above makes sense -- I may have just passed the safe caffeine threshold :)

(WOW, what an awesome discussion!  Thank you, Public Lab-bers!)