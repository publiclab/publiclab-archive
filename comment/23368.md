---
cid: 23368
node: [GSoC proposal: Mapknitter ORB Descriptor (w/ auto-stitching, pattern training, and live video support) and LDI revamp (major UI enhancements)](../notes/rexagod/03-11-2019/gsoc-proposal-mapknitter-orb-descriptor-w-auto-stitching-pattern-training-and-live-video-support-and-ldi-revamp-major-ui-enhancements)
nid: 18515
created_at: 2019-03-22 12:04:04 +0000
timestamp: 1553256244
uid: 564358
author: [rexagod](../profile/rexagod)
---

Hey there [@MaggPi](/profile/MaggPi)!

That gif only shows the working of the AS module, and none of the images were actually wired to/utilized any ORB algorithm in that particular example. Let me explain.

The gif in question makes use of two images to demostrate *only* the automatic stitching ability of the AS module. In that particular example, I've explicitly passed the coordinates where the second image is supposed to be stitched to the first one. Of course we can do that using ORB, but for now I guess, the ORB isn't that advanced and may give some pretty messed up/unwanted results every once in a while, hence completely depending on it might not be the a good solution for now, so, as is visible in section (d), I'm thinking of displaying a modal that shows how good both the images compare, and leaving to the user if they want to stitch it in a left/right/top/down manner, and then automate AS to take up those coordinates and stitch the images in the desired orientation. Does that make sense?

Also, thank you so much for showing your interest in my proposal! Appreciate it! ðŸ˜ƒ 

[rexagod](../profile/rexagod) replying to: [GSoC proposal: Mapknitter ORB Descriptor (w/ auto-stitching, pattern training, and live video support) and LDI revamp (major UI enhancements)](../notes/rexagod/03-11-2019/gsoc-proposal-mapknitter-orb-descriptor-w-auto-stitching-pattern-training-and-live-video-support-and-ldi-revamp-major-ui-enhancements)

