---
node: WATERCHESTNUT Big Picture
author: cfastie
created_at: 2013-07-30 14:41:52 +0000
timestamp: 1375195312
nid: 8926
cid: 6427
uid: 554
---



[cfastie](../profile/cfastie) replying to: [WATERCHESTNUT Big Picture](../notes/cfastie/07-23-2013/waterchestnut-big-picture)

----
Charlie, Some of the structure from motion programs that make 3D terrain models from aerial photos do not need any input other than the photos themselves (maybe including some EXIF data about the lens). These can take a long time to figure out how the photos overlap and eventually where the camera was for each photo. It took several hours to process the 76 photos for [this model](http://publiclab.org/notes/cfastie/07-15-2013/3d-tundra). If you give the program a hint about where the camera was for each photo, it can reduce computation time. I don't know how much this can improve the final result, because all the programs have to figure out the camera positions and orientations one way or another. But some programs will not work without GPS data for the camera for each shot. Pat, do those programs want x,y,z data? Do some also want orientation data (which way the camera was pointed)? Do these programs all make 3D models or is GPS data also used to make 2D maps from the air photos? Automatically stitching air photos into 2D maps with good ground control (georeferencing) would be an important advance over Microsoft ICE which does a good job stitching but can freely distort the photos to get them to stitch with no regard for geography.