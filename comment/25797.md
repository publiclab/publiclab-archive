---
cid: 25797
node: ![How can I calibrate a turbidity sensor?](../notes/wmacfarl/10-28-2019/how-can-i-calibrate-a-turbidity-sensor)
nid: 21316
created_at: 2019-11-04 20:21:19 +0000
timestamp: 1572898879
uid: 201929
author: bhickman
---

Hi wmacfarl,

Typically you would want to have some idea of the turbidity of whatever unknown sample you want to measure. If your measuring a freshwater stream, your maximum turbidity will probably be somewhere around 100 NTU. Once you have an idea of the maximum turbidity expected, then you should make your calibration solutions just beyond that limit (i.e. start with a solution around 150 NTU if you expect 100 NTU as your max). Once you have your maximum concentration solution, then you should make a series of more dilute solutions, including a pure water solution. This is usually done by taking some of you most concentrated solution and cutting it in half, by dilution, and repeating this process three or four times (i.e. you start with 100 NTU, then you would make 50 NTU, then 25 NTU...). 

If you know your sensor has a linear response over the turbidity concentration range you are calibrating, then you can skip the serial dilution and only measure the high concentration sample and pure water sample in order to generate your calibration curve. Typically you would expect a linear response in lower turbidity concentrations (maybe less then 50 NTU). At higher turbidity concentrations the linearity will break down. 

If you want to go down the path Markos is looking at (using neutral filters or something similar), I would suggest that you use those as a secondary standard. So you would first calibrate you instrument using NTU standards, then measure your secondary standard (neutral filter or the like) to get a NTU equivalent value for that standard. After that you can do without the NTU standards and only use the secondary standard. 