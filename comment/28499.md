---
node: GSoC 2021 Proposal: Geographic Features Refinement
author: barun1024
created_at: 2021-04-10 12:08:14 +0000
timestamp: 1618056494
nid: 26021
cid: 28499
uid: 647185
---



[barun1024](../profile/barun1024) replying to: [GSoC 2021 Proposal: Geographic Features Refinement](../notes/barun1024/03-24-2021/gsoc-2021-proposal-geographic-features-refinement)

----
>Are there even websites out there that can be set up to scrape for us? 
Or, would it be possible to write the scraping script, but to have it dump into an existing geoJSON service?

One way would be to schedule cron jobs for scraping and dumping data and leverage a microservice to serve that data. We can use `github-action` to schedule this too. [Ref](https://docs.github.com/en/actions/reference/events-that-trigger-workflows#scheduled-events) 

I am not exactly sure what do we want to `scrape`, since we already have an `api` for people and posts, hence I used the term `cache` to as to reduce the load on the `api`. Do we plan to use some external website which we would need to scrape for data?