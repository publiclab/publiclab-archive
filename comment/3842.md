---
node: PAR
author: cfastie
created_at: 2013-03-20 20:52:29 +0000
timestamp: 1363812749
nid: 6372
cid: 3842
uid: 554
---



[cfastie](../profile/cfastie) replying to: [PAR](../notes/cfastie/3-16-2013/par)

----
Dan, you are correct that all we want to know is how the light intensity varies across the sensor where the grating has spread out the spectrum. Unfortunately, we are using consumer digital cameras, and to make a colorblind sensor see in color, they use Bryce Bayer's 1976 system which inserts an array of color filters and an interpolation algorithm between us and those photons impacting the sensor. What the camera gives us is really rather messy, and not what we need for spectroscopy, although it can be used to make incredibly good color photos.

When certain colors hit the Bayer filters, only one filter transmits them, but other colors pass through all three filters and inform three different color channels (r,g,b,). So for some parts of the spectrum, there is information in all three color channels. A simple way of combining that information is to average the three channels. The sum of the three channels does not have any more information that the mean. Multiply the mean by 3 and you get the sum -- it's just scaled differently. Multiply the mean or the sum by any factor and you have the same information. Graph them all with the Y axis scaled differently for each and the graphs can overly each other perfectly.

The issue is that the Bayer system is not designed to allow us to precisely compare the intensity of light hitting two different places on the camera's sensor if that light was not the same color. This is mostly because the color channels are not discreet, e.g., the blue channel can have information about green light -- the channels overlap. Where the green and blue channels overlap, the blue channels picks up as the green channel sensitivity fades out, but the transition is imperfect. Summing or averaging across that transition produces conspicuous artifacts (values higher than on either side of the overlap). In addition, different wavelengths of green light will be recorded in the green channel as having different intensities, even if the incoming light had identical intensity for all wavelengths. So take a photo of a continuous spectrum with identical intensity at all wavelengths, and the photo will record wild fluctuations in intensity across the spectrum. For a single camera, these fluctuations are probably constant and predictable. So it should be possible to derive a calibration routine which corrects each wavelength for intensity. I guess. 