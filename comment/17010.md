---
node: "Test images" for multispectral image processing
author: warren
created_at: 2017-07-08 17:47:38 +0000
timestamp: 1499536058
nid: 14565
cid: 17010
uid: 1
---



[warren](../profile/warren) replying to: ["Test images" for multispectral image processing](../notes/warren/06-21-2017/test-images-for-multispectral-image-processing)

----
Hi, Ned - i'm not asking about calibration at this point, just for a way to empirically test (in the sense of automated testing -- https://en.wikipedia.org/wiki/Test_automation) to confirm that various pieces of software are correctly implementing NDVI and outputting a correct image based on a given source image. By confirming this programmatically (literally running it and then doing a computed diff against a known correct output image) we can have an empirical way to ensure that a given piece of software produces an agreed-upon "correct" output, without having to specify a particular methodology. For NDVI, we really have to consider more than just the mathematical expression, because we have to consider how that's presented as R, G, B pixel values from 0-255, and different ways of achieving this (per-pixel math, vs. GPU-based 'shader' approaches) may mean the implementation varies, but the output of course should not. 

So what we're looking for is an ideal "before and after" image pair showing an input image and a "correct" output NDVI result image. 

[@ccpandhare](/profile/ccpandhare) is approaching this here: https://publiclab.org/questions/ccpandhare/07-08-2017/how-to-verify-if-my-programmatically-generated-ndvi-version-of-an-image-is-correct

and here; https://github.com/publiclab/image-sequencer/issues/34