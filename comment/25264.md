---
node: UI principles for offline apps
author: icode365
created_at: 2019-08-19 17:23:59 +0000
timestamp: 1566235439
nid: 20580
cid: 25264
uid: 553778
---



[icode365](../profile/icode365) replying to: [UI principles for offline apps](../notes/warren/08-19-2019/ui-principles-for-offline-apps)

----
Yes, I agree that there are some potential pitfalls that can cause inconvenience to the user as well as the developers.
These are some important things to keep in mind when dealing with Progressive web apps, thanks [@warren](/profile/warren) ðŸ˜ƒ 

So,

- **Version transparency**: This is really important and is not currently implemented in community-toolbox, definitely a follow-up. Showing a  simple hash of the latest commit (latest on the deployed version) can turn out to be so helpful in the future.
This can be as simple as,

[![pic.png](/i/34660)](/i/34660?s=o)


- **Status and source of current version**: Whenever we're designing a PWA that supports offline access, the main goal should be to show the latest copy of data to the user as long as he/she is connected to the internet. When not, the cached version of the data should be displayed and that should be as recent as possible.
Offline access logic for community-toolbox is designed keeping above thought in mind. It follows _Network with Cache Fallback Policy_ combined with constant cache updation cycles, which makes sure that
  - User is served with the latest copy of data as long as he/she is connected to the internet. With every successful fetching of data, the cache is updated with the latest info that is received.
  - When the user goes offline, the cached data is displayed which contains the data from the last successful fetch that happened.

So this ensures that cache is getting updated with every successful fetch from the internet and user is guaranteed to get the latest possible copy of data.

But showing the status is a very useful thing to have anyways!


- **User ability to flush cache**: This is a useful utility, but we need to make sure that we are able to serve the fresh copy of data beforehand, otherwise, the page would not be having any data as the cache will be flushed and fetching from the net won't be able to get any new data (happens when data source puts a limit on the number of requests you can make in a certain amount of period).
Like, in case of Github API, they limit the unauthenticated requests and you cannot make more than 60 req/hr.
So precautions should be taken when clearing out the cache.



