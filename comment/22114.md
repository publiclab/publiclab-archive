---
node: GSoC proposal: Mapknitter ORB Descriptor (w/ auto-stitching, pattern training, and live video support) and LDI revamp (major UI enhancements)
author: warren
created_at: 2019-03-11 19:44:45 +0000
timestamp: 1552333485
nid: 18515
cid: 22114
uid: 1
---



[warren](../profile/warren) replying to: [GSoC proposal: Mapknitter ORB Descriptor (w/ auto-stitching, pattern training, and live video support) and LDI revamp (major UI enhancements)](../notes/rexagod/03-11-2019/gsoc-proposal-mapknitter-orb-descriptor-w-auto-stitching-pattern-training-and-live-video-support-and-ldi-revamp-major-ui-enhancements)

----
 This is really great, thank you [@rexagod](/profile/rexagod)!!! A very powerful and interesting proposal.

I'm interested in how the process breaks down into specific functions that are re-usable -- what are the useful subcomponents of this project! Such as - could it have such sub functions as:

* `lib.getPoints(image)`
* `lib.findPointMatches(pointsArray)`
* `lib.findPosRelativeToImage(imgA, imgB)`
* `lib.findPointsInImg(pointsArray, img)`

These may not be exactly right, but trying to think like this to give us a set of tools that could be reconfigured in different ways, such as to run on video frames, to turn a video stream into a large image, to move Leaflet image overlays around, things like that. 

There might also be listeners, like `lib.onFindMatch(fn)` which would then run `function(matchedPoints)` or something... all these would be great too because they'd be testable!

What do you think of breaking down the architecture a little bit like this? Thank you! This is off to a great start!