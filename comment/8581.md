---
node: Mobius, stripped
author: cfastie
created_at: 2014-03-25 21:22:00 +0000
timestamp: 1395782520
nid: 9296
cid: 8581
uid: 554
---



[cfastie](../profile/cfastie) replying to: [Mobius, stripped](../notes/cfastie/09-06-2013/mobius-stripped)

----
That's a really clever idea, and I think it might work. However, it assumes that:

1.  The photos must be simultaneous if anything in the scene is changing.  That can be done.
2. The IR block filter cannot change the amount of visible light reaching the sensor. That assumption is probably not met, although most IR block filters probably block only very little R, G, or B.
3. The exposure has to be such that the same amount of RGB is captured by equivalent pixels in both cameras. I don't know how you would do that. You would have to know how much of the light reaching the sensor was visible versus NIR. If you knew that, you would already have the answer. But you can probably get a facsimile of NDVI, which is all we ever get anyway.

It's an easy thing to test if you have a camera with no IR block filter. Take some test photos with the unmodified and full spectrum camera, then put a long pass 720 nm filter in front of the full spectrum camera and take a third photo. Compute an NDVI image using both methods. Report back.

