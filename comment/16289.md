---
node: Bot for Publiclab
author: ryzokuken
created_at: 2017-03-04 18:26:32 +0000
timestamp: 1488651992
nid: 13972
cid: 16289
uid: 493113
---



[ryzokuken](../profile/ryzokuken) replying to: [Bot for Publiclab](../notes/ryzokuken/02-28-2017/bot-for-publiclab)

----
Hey [@liz](/profile/liz)! One simple and solid solution could be to make our bot "dumb" by hardcoding certain special interactions. In this case, the bot will realize that "[@plotsbot](/profile/plotsbot) help" means that the person is asking for help and "[@plotsbot](/profile/plotsbot) questions [@ebarry](/profile/ebarry)" would mean that the speaker (or the type-er :P) is interested in all the questions asked by user [@ebarry](/profile/ebarry) on publiclab.org.

An alternative would be to use NLP and ML in our bot from Day 1 (because it can always be added later in the model I described above). While certainly a few thousand times difficult to achieve than the simpler alternative, this would allow the bot to not only understand Natural Language, but also provide better responses based on its past experiences. Another problem that arises with ML is, that I don't know to what extent can that technology be tested (Like... really, how can we predict how the bot will act?)

As of the brownie point system, I respect your stance, and feel that a single model is sufficient for community appreciation. 

Should the community and general administration agree with the proposal, a good next step (in my opinion) would be to make a formal design document that formally states the purpose and important details of the bot and how it will operate. That document would be used be contributors like me as a reference.

Thanks