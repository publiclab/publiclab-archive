---
node: Question:  Why average? And what happens to the second Green?
author: cfastie
created_at: 2016-05-05 21:21:08 +0000
timestamp: 1462483268
nid: 13081
cid: 14552
uid: 554
---



[cfastie](../profile/cfastie) replying to: [Question:  Why average? And what happens to the second Green?](../notes/viechdokter/05-05-2016/question-why-average-and-what-happens-to-the-second-green)

----
I think if you capture camera raw you have a single number (DN) for each pixel and you know what kind of Bayer filter that pixel was under. The DN must be 12 or 14 bits? 

If you knew the spectral sensitivity of the sensor, you could correct the raw data for intensity at each wavelength (e.g., in a photo of a diffraction pattern). 

You would sacrifice the camera's sophisticated corrections for noise and lens distortion, including chromatic aberration, vignetting, etc, but you would probably be way ahead of what you get from a jpeg.