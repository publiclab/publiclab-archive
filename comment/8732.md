---
cid: 8732
node: ![Infragrammar with HSV color model](../notes/warren/08-24-2013/infragrammar-with-hsv-color-model)
nid: 9054
created_at: 2014-04-11 14:38:15 +0000
timestamp: 1397227095
uid: 1
author: warren
---

As i pointed out [in the comments here](/notes/warren/04-10-2014/mobius-action-cam-infragram-tests) yesterday, this HSV approach is pretty interesting and conceptually fun, but not ideal for real work with LUTs. I spent some time thinking about it and did some sketches of a new interface:

[![colormapping.jpg](https://i.publiclab.org/system/images/photos/000/003/622/medium/colormapping.jpg)](https://i.publiclab.org/system/images/photos/000/003/622/original/colormapping.jpg)

This might also include the "auto adjust" pictured which would basically just auto-set the range of the color table it'd actually use. We could let people do that with a couple sliders, too, as a more advanced feature, but automating in a consistent way is probably best. 

The algorithm would be pretty similar to HSV, except that instead of looking up a color by converting from a 0-1 range into a color value from the color wheel, we'd just look up the color from the selected LUT, where the left edge is 0 and the right edge is 100%. Sorry if that's obvious. 

I'm not sure if the LUTs should be computationally generated (Ben G provided for this in his own color mapping system -- his version of Chris's default green-cutoff LUT is actually generated, not stored) or just based on images we upload to the server. It could get kind of weird if we wanted to just do 6 block colors with no gradients... maybe we can stick to just images for now, not equations. 