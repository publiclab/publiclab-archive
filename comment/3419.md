---
node: Additive Image Stacking In Spectroscopy
author: cfastie
created_at: 2013-02-14 16:20:38 +0000
timestamp: 1360858838
nid: 5973
cid: 3419
uid: 554
---



[cfastie](../profile/cfastie) replying to: [Additive Image Stacking In Spectroscopy](../notes/ulao2/2-13-2013/additive-image-stacking-spectroscopy)

----
This is really interesting. In theory, or ideally, when you take a digital photo of a diffraction pattern, each pixel on the sensor is being impacted by light of a single wavelength. Light of that single wavelength has to pass through the Bayer filters, and although these are designed to pass only one range of colors each (R, G, or B), there is overlap and some wavelengths can pass through all three filters. So even when photographing a diffraction pattern in which all the wavelengths should be separated spatially on the sensor, each pixel can collect and save information in two or more color channels. 

In the area of the diffraction pattern that is in the middle of the red range, for example, most of the information that ends up in the blue and green channels might be noise â€“ it was wavelengths that got loose inside the spectrometer and ended up in the wrong place in the image. Or it is other types of noise, but it might not be helpful to include it in our data. In the two parts of the spectral image that are between the R, G, and B ranges (around 490 nm and 580 nm) the wavelength of interest is getting through two of the  Bayer filters. That information is useful and should be saved. There might never be a reason to save information from all three channels (but the actual behavior of Bayer filters may not justify this statement).

So a very simple approach would be to use only the single R, G, or B channel except in the ranges from 480-510 nm (where you add the B to the G) and from 570-610 nm (add the G to the R). I am completely ignoring the question of what to do in the near infrared, but using all three channels probably makes sense.

This approach can have important consequences. It is very common to overexpose bright peaks in an image of a diffraction pattern. The primary channel for that color will be blown out and have no data to resolve the peak. A secondary channel which is less sensitive to that color could be exposed better and resolve the peak well. By adding (or averaging) these two peaks the spectrograph can show a sharp peak and save the day. This can happen even outside of the two overlap areas given above between the R, G, and B ranges. So with this type of new approach implemented, it might be more important to avoid overexposure (this is really important all of the time though).
