---
node: Brainstorming for Summer of Code 2019
author: MaggPi
created_at: 2019-01-12 22:11:27 +0000
timestamp: 1547331087
nid: 18047
cid: 21708
uid: 501996
---



[MaggPi](../profile/MaggPi) replying to: [Brainstorming for Summer of Code 2019](../notes/warren/01-02-2019/brainstorming-for-summer-of-code-2019)

----
Glad to see the experimental tools category!   Like this since it permits  end to end analysis of an environmental monitoring effort.  Many GSOC  efforts are software only; having efforts that focus on software (with  hardware) creates more design options and a better understanding of user experience and trade-offs.

Some brainstorming ideas: 
-Drones.   - Drone imaging is rapidly maturing and should be considered as part of the Public lab remote sensing options.  Maybe something like adding NDVI real time collection with other  mapping tools such as  https://www.opendronemap.org/ .

-Environment Monitoring IoT   - Public lab offers  great value by providing distributed sensing  tools for environmental monitoring.  Internet of Things (IoT)  has the potential to lower sensor  cost and provide a common modular approach.   Efforts such as Purple Air  and  Cogqui are a start but a common collection method and interface such as  https://openconnectivity.org/  is needed. 

-‘Microscope live stitching blob detection and extraction of larger images from a panning live video feed’ is a great idea but I  also know this gets complicated quickly. Some thoughts:

-  Image J has a stitching option (https://imagej.net/Image_Stitching and https://github.com/USNISTGOV/MIST/  but seems to depend of very precise stage control.  This may be hard to replicate on low cost equipment.
- It may be possible to have a dual use generic video stitching application suitable for microscopes (object moves) and aerial reconnaissance (camera moves).
- I tried some basic some basic blob detection (color, shape) on my GSoC 2018 (https://publiclab.org/notes/MaggPi/03-20-2018/gsoc-proposal-computer-vision-enhancements-for-raspberry-pi-based-public-lab-science-projects) effort and they worked but they also required very careful parameter selection or you get false detections.  The current trend is to have AI/Deep Learning tools that fine tune  the ‘blob’ search algorithms.  Typically this requires some type of data classification (see for example: https://www.zooniverse.org/projects/anaelisa24/sounds-of-new-york-city-sonyc ) effort.
- Also don’t forget the need for flat field correction(s).  Lens lighting variations will probably be more noticeable when repeated  in a stitched image. 
