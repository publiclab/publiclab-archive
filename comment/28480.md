---
node: GSoC 2021 Proposal: Geographic Features Refinement
author: warren
created_at: 2021-04-09 18:19:34 +0000
timestamp: 1617992374
nid: 26021
cid: 28480
uid: 1
---



[warren](../profile/warren) replying to: [GSoC 2021 Proposal: Geographic Features Refinement](../notes/barun1024/03-24-2021/gsoc-2021-proposal-geographic-features-refinement)

----
Hi Barun! Thanks so much for this proposal, it looks great. Some thoughts I wanted to share:

- I'm thinking about the "fallback" or most basic pathway in your excellent flow diagram - for example, an activity page on PublicLab.org might say "copy paste _this text_ into an issue" (linking to a template text file) but we might also have an issue template set up. Thinking on how people who don't have a github account, or for whom GitHub is an unfamiliar place, might most smoothly navigate this, and if there are things we want to do to improve the process for them.
- I love the idea that GitHub Actions can do a lot here. I also think GitPod could help - that is, once GitPod builds, we can say something like "click the 'open in gitpod' button to try out the layer" maybe?
- I also wonder how independent the code changes will be. That is, what if someone used our system to just make their own map, quite apart from LEL entirely? Would some level of compartmentalization make this possible? Like, could there be a line that says "if you just download the code from this PR branch, you can just run it yourself" or "copy paste the contents of this file to add just this new layer into any Leaflet map?" These arent required at all, but just brainstorming -- if this functionality had broader usage it might attract a broader base of contributors to keep maintaining it!

Regarding the micro-service idea, i'm curious what shortcuts we can take. I can imagine that this is relatively simple for a micro service. But, it's good to think about -- are there microservice templates or infrastructures we could build on to reduce the amount of code or infrastructure we'd need to build ourselves? Are there even websites out there that can be set up to scrape for us? Or, would it be possible to write the scraping script, but to have it dump into an existing geoJSON service and rely on their code's query optimization? I think there could be many different answers to this and I don't think we have to immediately know the best answer, but perhaps it's worth researching a bit to see what's out there and what the possibilities are.

Thanks so much Barun!!! ðŸŽ‰ 