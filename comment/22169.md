---
node: GSoC proposal: Mapknitter ORB Descriptor (w/ auto-stitching, pattern training, and live video support) and LDI revamp (major UI enhancements)
author: rexagod
created_at: 2019-03-16 18:22:04 +0000
timestamp: 1552760524
nid: 18515
cid: 22169
uid: 564358
---



[rexagod](../profile/rexagod) replying to: [GSoC proposal: Mapknitter ORB Descriptor (w/ auto-stitching, pattern training, and live video support) and LDI revamp (major UI enhancements)](../notes/rexagod/03-11-2019/gsoc-proposal-mapknitter-orb-descriptor-w-auto-stitching-pattern-training-and-live-video-support-and-ldi-revamp-major-ui-enhancements)

----
Hey [@sashadev-sky](/profile/sashadev-sky)! I'm glad you like it! ðŸ˜ƒ Apologies for not being able to chime into the multiple image PR, though I've been meaning to for a while now, and definitely will! I've been nonetheless following up on it and it looks very promising! ðŸ‘ 

[@warren](/profile/warren) Please refer the text/images below and do let me know if there's anything else I can help with!

![pixels](https://user-images.githubusercontent.com/33557095/54478059-4256e100-4834-11e9-988d-bf1d67ff02b4.png)

If we assume the canvas to be say, 640x480, the ORB will run against 307200 pixels (stored in `matches` array above) against every pixel in the original pattern. Visualize this as the bigger canvas (let's call it `screen canvas`) having it's bottom left corner at the origin with the measurable units on both axes being multiples of a pixel. Similarly let's call the smaller (inset) canvas `pattern canvas`. That being said, let's get down to the questions.

 > I want to know how you'd pass in 2 images, and how we'd format the identified points that were handed back out?

The `pattern_xy` (matched points in smaller canvas) and `screen_xy`(corresponding matched points in larger canvas) arrays are globals and thus can be accessed after they have been assigned values from wherever we'd want to.

> How we'd "save" a point (in what format) that we want to reference again later?

Similar to above, the points are already saved in the two arrays which can be traversed in a level-order fashion to get all the identified points in the canvas. As far as the format for storing these points is concerned,  `pattern_xy` and ` screen_xy` are object arrays that store the xy coordinates of the identified points. Please refer to the snippet below.

```js
// construct correspondences
            for (var i = 0; i < count; ++i) {
                var m = matches[i];
                var s_kp = screen_corners[m.screen_idx];
                var p_kp = pattern_corners[m.pattern_lev][m.pattern_idx];
                // identified points in the smaller canvas
                pattern_xy[i] = { "x": p_kp.x, "y": p_kp.y };
               // identified points in the larger canvas
                screen_xy[i] = { "x": s_kp.x, "y": s_kp.y };
            }
```

> And how to (most importantly) return the location of a point in Image B but using the coordinate space of Image A. (i.e. what point in Image A does a given matched point in Image B correspond to)?

The xy sets on the left represent matched points in the pattern canvas `pattern_xy` and those on the right represent the corresponding matched points in the screen canvas `screen_xy`.

![Screenshot from 2019-03-16 21-21-07](https://user-images.githubusercontent.com/33557095/54478058-41be4a80-4834-11e9-930f-36a1c523c438.png)

If any pixel (on the whole canvas) has a good match data, we send that into those arrays. 

```js
if (match_mask.data[i]) {
                        pattern_xy[good_cnt].x = pattern_xy[i].x;
                        pattern_xy[good_cnt].y = pattern_xy[i].y;
                        screen_xy[good_cnt].x = screen_xy[i].x;
                        screen_xy[good_cnt].y = screen_xy[i].y;
                        good_cnt++;
}
```

Finally adjust the corresponding "scale" for the main canvas.

```js
 // fix the coordinates due to scale level
                    for (i = 0; i < corners_num; ++i) {
                        lev_corners[i].x *= 1. / sc;
                        lev_corners[i].y *= 1. / sc;
                    }
```

> Finally, maybe as important as that last, can we return the four corner points of Image B in Image A's coordinate space? So that we can position Image B relative to Image A?

The `shape_pts` array specifically stores the coordinates for the given purpose derived from the `homo3x3.data`, a homography pin-point helper that serves the sole purpose of what its name suggests, and is rendered out as below.

```js
var shape_pts = tCorners(homo3x3.data, pattern_preview.cols * 2, pattern_preview.rows * 2);
```

```js
            ctx.moveTo(shape_pts[0].x, shape_pts[0].y);
            ctx.lineTo(shape_pts[1].x, shape_pts[1].y);
            ctx.lineTo(shape_pts[2].x, shape_pts[2].y);
            ctx.lineTo(shape_pts[3].x, shape_pts[3].y);
            ctx.lineTo(shape_pts[0].x, shape_pts[0].y);
```
We can also adjust the scale in the larger canvas (as above) to display the "matched" box in the smaller one too.

Thank you!!