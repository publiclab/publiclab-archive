---
node: GSoC proposal: Computer Vision enhancements for Raspberry Pi based Public Lab Science Projects
author: MaggPi
created_at: 2018-08-15 02:05:43 +0000
timestamp: 1534298743
nid: 15978
cid: 20394
uid: 501996
---



[MaggPi](../profile/MaggPi) replying to: [GSoC proposal: Computer Vision enhancements for Raspberry Pi based Public Lab Science Projects](../notes/MaggPi/03-20-2018/gsoc-proposal-computer-vision-enhancements-for-raspberry-pi-based-public-lab-science-projects)

----
This note is a GSOC phase 3 summary and provides a complete set of links related to the project.     
Google Summer of Code proposal available at: https://publiclab.org/notes/MaggPi/03-20-2018/gsoc-proposal-computer-vision-enhancements-for-raspberry-pi-based-public-lab-science-projects

 Code descriptions can be seen at https://publiclab.org/profile/MaggPi.
Video demos at: https://www.youtube.com/channel/UCbyyYOlNo87CXJ39h3wqXZA
Github readme file contains a list of all programs with a short description:
https://github.com/MargaretAN9/Peggy/blob/master/README.md

Phase 3 activities involved several areas:
-https://publiclab.org/notes/MaggPi/07-17-2018/high-dynamic-range-hdr-imaging-revisited
-https://publiclab.org/notes/MaggPi/08-09-2018/raspberry-pi-manual-camera-control
-https://publiclab.org/notes/MaggPi/08-14-2018/computer-vision-observations-of-elodea-plant-cells
-https://publiclab.org/notes/MaggPi/07-18-2018/ndvi-micrsocopy
- https://publiclab.org/notes/MaggPi/08-03-2018/ngb-ndvi-video-optimization-red-blue-manual-gain-control
-https://publiclab.org/questions/MaggPi/07-24-2018/ndvi-led-simulator

HDR imaging, manual camera controls and Elodea microscope observations  look at different ways to extend dynamic range and  display images.  
NDVI was explored in NDVI microscopy and NGB-NDVI video optimization.  In addition, a NDVI LED Simulator was proposed as a potential method to calibrate NDVI data.  
Software also was developed to display real time spectral data output.  Work to separate orders and conduct calibration by colormaps were frustrated by signal crossover between RGB channels.    

In general, the programs demonstrate a transition from ‘snapshot’ imaging to processing data at video rates with manual control of camera settings.  The ability to adjust image properties in real time provides a quick way to control image quality and optimize for different computer vision tasks.  While resolution is limited in real time processing, the same settings can be used for higher resolution images which can then be processed by image sequencer (https://publiclab.github.io/image-sequencer/examples/#steps=). 

My only regret is that I didn’t have the time to look at problems discovered along the way.  Issues like real time flat field correction and keeping focus from visible to near infrared are two annoying areas that deserve a second look.  It may be worthwhile to look at how computer vision could compensate for optical problems as well as provide different lens options.   

My last comment is I would like to thank all my mentors [@amirberAgain](/profile/amirberAgain), [@warren](/profile/warren), [@icarito](/profile/icarito) as well as those who provided help, comments, and encouragement [@cfastie](/profile/cfastie) [@liz](/profile/liz).  I learned so much but I also know I have much more to learn.  While the programs provide a way to get started with real time computer vision techniques for Public Lab kits, possible future applications are unlimited.  
