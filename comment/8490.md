---
cid: 8490
node: ![Automatic Spectrometer Calibration and Offline SWB - GSoC 2014 Proposal](../notes/Sreyanth/03-04-2014/automatic-spectrometer-calibration-and-offline-swb-gsoc-2014-proposal)
nid: 10103
created_at: 2014-03-13 19:26:33 +0000
timestamp: 1394738793
uid: 1
author: warren
---

OK, my thoughts -- very lengthy! I had a while on an airplane to really dig into this.  Also Dave posted since I did, so maybe there's some overlap with what he said. Take a deep breath, here we go!

**Auto digitization:** along with auto-calibration, what about auto-detection of the clearest-lit region of the video output to use -- perhaps relating to [Dave Stoft's](/profile/stoft) recent work on "HDR" spectra, and/or reading/averaging various lines to get a clearer, less noisy, and well-exposed spectrum. It's worth looking at if existing overexposed spectra *do have* enough data above and below the chosen cross-section to make a better-exposed calibration. But often spectra images are curved, so it may not be a simple issue of moving up or down... but i guess if the sampling line is adjusted in the capture interface (and recorded in the device profile) then it would be OK. 

While using some advanced techniques to get well-exposed spectra would be great, it could get quite messy unless we have a good systematic way to record how these digitizations of images were performed. This could relate to the idea of "recipes" which is written in some Github issue (remind me to look for the issue) where the manner in which the graph is generated from the spectrum is recorded in the device profile as a sequence of coordinates and such: "x1,y1,x2,y2,spread" where spread is the # of pixels above and below the line to average in.  

**Re: [#4:](/n/4:)** will including manual calibrations necessarily improve the automated calibration? could it make an auto-recognition more likely without allowing poor manual calibrations to make the actual scaling of the autocalibration less accurate?

**Offline SWB:** use localStorage (a local key:value sqlite-backed database in HTML5) instead of local files to store spectra. You can dump the dataUrl into the value, in a JSON object. Chris is talking about the ability to upload images, which is not the same as the live capture interface running offline. People have asked for the ability to live-analyze, calibrate, and use the whole Capture interface offline. Obviously they can't run matching, but you might be able to design your auto-calibration system to run offline. Don't let this distract you from designing a great auto-calibration tool though -- if it works better do to it server-side, that's more important. Key features that don't already exist for offline include mainly:

* ability to store spectra with their calibration, for later easy upload
* some kind of prompt when you reconnect that says "You have 23 offline stored spectra. (Upload these now)"
* maybe... a way to download the spectra images with the calibration data etc. stored in exif tags? or something? Or encoded along the bottom edge of the image as pixels or something crazy, for later upload... but this seems like a waste of time compared to the other challenging - and very important - features we're discussing. 

**Secure uploading:** do you think requiring a user login is not secure enough?

**Using color instead of just ratio of distances for recognition:** I worry that overexposure (sometimes in all 3 color channels!) or camera variation might make color a poor indicator, but I'm not confident about my doubts either... it could work! My hope was that my original approach of ratio of distances between major peaks could be improved by making it the ratio of distances between each peak and some absolute location. Consider that sometimes people miss near-UV peaks or aren't recording infrared peaks. Also consider that infrared peaks can show up as all kinds of weird colors depending on the Bayer filters. So this is a complex question, deserving of some empirical attempts. Maybe also just the ratios between *all* possible peak pairs, or something. Surely there's good literature on this already out there, perhaps for general pattern matching, or for matching bar codes.

**Non-linear calibration:** I think this is a lower priority, at least insofar as it should not stop fast development of a linear calibration first. This could be related to the recipes idea, like "x1,y1,x2,y2,x3,y3,spread" in terms of how it's recorded and displayed 
