---
cid: 15533
node: ![Common low-cost technique limitations and strategies for impact](../notes/gretchengehrke/09-29-2016/common-low-cost-technique-limitations)
nid: 13508
created_at: 2016-09-29 20:48:28 +0000
timestamp: 1475182108
uid: 1
author: warren
---

While it's important to be really clear on **whether a technique is adequate to your needs and goals**, there are lots of ways less precise techniques can play a role in monitoring. 

And sometimes, as a technique is being refined (as many are on this site), it's capable of an easier form of data collection far before it reaches it's eventual and more ambitious goals. That's why it can be hard to talk about whether something "works" -- it may work for one use, but not for another. 

I had a few ideas on why to use more accessible tools even if they're not (yet, or ever) an equal match for more formal techniques:

1. collecting data at different times/places than official data to highlight its potential blind spots and advocate for a different test design
2. for use in long-term "trend" monitoring and early warning systems -- for example if you see a sudden spike in a reading, even if you can't be sure what caused it (this is related to the first example)
3. in outreach, skill-building and training to prepare and refine methods for the upcoming availability of better sensors
4. to highlight and communicate the need for better monitoring, through public involvement and outreach, and to expose how testing works in order to give the public better insight into testing approaches