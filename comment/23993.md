---
node: GSoC proposal: Mapknitter ORB Descriptor (w/ auto-stitching, pattern training, and live video support) and LDI revamp (major UI enhancements)
author: justinmanley
created_at: 2019-04-26 03:14:58 +0000
timestamp: 1556248498
nid: 18515
cid: 23993
uid: 421556
---



[justinmanley](../profile/justinmanley) replying to: [GSoC proposal: Mapknitter ORB Descriptor (w/ auto-stitching, pattern training, and live video support) and LDI revamp (major UI enhancements)](../notes/rexagod/03-11-2019/gsoc-proposal-mapknitter-orb-descriptor-w-auto-stitching-pattern-training-and-live-video-support-and-ldi-revamp-major-ui-enhancements)

----
[@rexagod](/profile/rexagod) this is an amazing proposal. great job!

+1 to [@warren](/profile/warren)'s inclination towards modularity. You're on the right track, especially with the code samples in your recent comments. I would encourage you to go even further in this direction. A useful exercise might be to write the code for extracting features, matching points, and computing the homography without any reference to browser APIs or data structures. As far as I can tell, the computer-vision code should be environment-agnostic. You might think about writing it outside of the browser with a nodejs harness which feeds in image arrays and checks that the values are as expected. Ideally, your code shouldn't need any special rendering code at all: if it outputs data in the format that Leaflet.DistortableImage can understand (e.g. image + the coordinates of the warped corners, in a common coordinate space), then you may be able to use Leaflet.DistortableImage to handle the rendering altogether.

One thing I don't see covered in this proposal is how the uploaded images will be aligned to the base map once they been automatically stitched together. Is this within the scope of your proposal? Or will users manually align the stitched image conglomerate against the base map?

Separately, I wonder about the performance of these computer vision operations in the browser. Do you have a sense of how computing keypoints / matches / homography perform in the browser? These operations are all extremely compute-intensive (especially on the GPU), and I have found that JS libraries for numerical computation are not always as robust or performant as their server-side counterparts (e.g. OpenCV). Have we considered the tradeoffs of doing these computations in the browser vs. on the server?

great job again -- you've covered the problem so thoroughly, from feature detection to matching (using RANSAC!) to computing the homography. I'm excited to see this project develop.