---
node: Noise by colour
author: warren
created_at: 2016-04-21 21:35:55 +0000
timestamp: 1461274555
nid: 12994
cid: 14379
uid: 1
---



[warren](../profile/warren) replying to: [Noise by colour](../notes/viechdokter/04-17-2016/noise-by-colour)

----
Hi, all -- 2.55 is definitely related to the 0-255 value. The code that generates the CSV is here:

https://github.com/publiclab/spectral-workbench/blob/675d11793927fa2507eebd6c075d3304711842b7/app/helpers/spectrums_helper.rb

The original data the CSV is based upon is encoded here: https://github.com/publiclab/spectral-workbench.js/blob/ef52eac98c31066bf438fd05c09b5241e64487ae/src/SpectralWorkbench.Spectrum.js#L119-L144

If it's an error, we should definitely fix it! There's also potential for a simpler implementation in the new spectral-workbench Node.js implementation. I recently coded a CSV **decoder** here:

https://github.com/publiclab/spectral-workbench.js/blob/ef52eac98c31066bf438fd05c09b5241e64487ae/src/SpectralWorkbench.Spectrum.js#L29-L39

And opened an issue for a new CSV **encoder** here: https://github.com/publiclab/spectral-workbench.js/issues/12

There seem to be two places to fix it if this is indeed wrong:

1. ensure output is max 255 instead of max 2.55 by multiplying by 100
2. displaying/storing all data in 0-255 instead of percentages (we'd have to be sure this doesn't affect legacy data/operations, and doesn't conflict with other math we do)

the Node.js package is very thoroughly tested, so if we did introduce such a change, it'd be pretty easy to see if it breaks anything. 