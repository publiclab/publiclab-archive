---
node: What are important aspects to consider about replication on the website and in the community?
author: cfastie
created_at: 2016-09-30 01:52:42 +0000
timestamp: 1475200362
nid: 13500
cid: 15543
uid: 554
---



[cfastie](../profile/cfastie) replying to: [What are important aspects to consider about replication on the website and in the community?](../notes/liz/09-28-2016/what-are-important-aspects-to-consider-about-replication-on-the-website-and-in-the-community)

----
Gretchen has a good point that the term replication has very different meanings when applied to builds, modifications, field tests, observations, experiments, or monitoring deployments. The meaning of replication that is generally associated with scientific research is not the meaning that will typically apply when someone tries to repeat a build, modification, field test, or observation that someone has described in a research note. To avoid confusion and pretension, it might be better to use a phrase like “I tried this” which can be applied to any category of activity.

Jeff’s idea of presenting a quiz to the poster can collect crucial information about the nature of the attempt to repeat someone else’s activity.

Quiz:

- Hi. You have started to post your “I tried this” results. The activity you tried is [name of note].  
- Did you try to repeat all of the steps in the activity?  
- What numbered steps in the activity did you try? (describe them if there are no numbers)  
- Are you also reporting on additional steps that were not in the original activity?  
- Was your result different from the one described in the original post?  
- If your result was different, was it because: A….B….C….D…Other.  
- Do you think your attempt to repeat this activity was successful?  

- Thanks. Please describe your experience below. …  

I am a little worried that this approach is creating a bit of a monster. My guess is that many hundreds of people try things they learn about in research notes, but very few of them post research notes about their experience. Posting useful research notes is not for everyone, and can be hard work. It can also be incredibly intimidating unless you are familiar with Public Lab and aware that we are happy almost every time anybody contributes anything in a research note. To most people it’s just too hard to know if you’re doing it right when you post, or whether the community will value your post.

The proposed changes associated with the activity/repetition types of posts have the potential to scare away even more potential posters. There will suddenly be much more to learn about how to do it right, and many more ways to do it wrong. 

For example, the new question interface is often used by people who have tried an activity (e.g., using the Infragram or spectrometer) and have a question about the process or result. Should those people instead post an “I tried this” note? How do people decide which to do?

If you tried only one of the four steps in an activity, is it okay to post an "I tried this?" If you followed steps 1-3 and then added your own steps 4-5, is it okay to post an "I tried this?" If you build a new spectrometer that has no components in common with existing builds (e.g., Ebert when it was posted), is this a new activity or an "I tried this" with (lots of) modifications? How do you write the rules to guide people through this?

Posting an original activity requires that people determine which of the categories (build, observation, experiment, etc) it fits into. That’s hard, although repeating an activity (“I tried this”) does not require making this decision. However, reporting intelligently on your experience repeating an activity will require understanding the difference between builds and modifications, and between observations and experiments. This really raises the bar for all posters. Raising the bar is a good thing, unless few people can get over it.

As Gretchen describes, determining whether repeating a previous activity was successful or not will almost never be straightforward. Every category of activity needs to be evaluated in a different way. Training people to figure this out will be onerous and asking people to do it could drive them away. 

It might be best to let the poster who tried to repeat an activity report whether they thought it was successful or not. If they are convinced it was successful, then it was. Trying to pin down whether a repetition of an activity validates the activity or provides “replication” in some scientific way might be too much to ask. 

It's possible that this entire new structure could be much more relaxed and still provide the collaborative, community building benefits which seem to be the main goal of the project.

Chris
