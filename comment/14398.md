---
cid: 14398
node: ![Comment piece in Nature about peer review](../notes/liz/04-21-2016/comment-piece-in-nature-about-peer-review)
nid: 13010
created_at: 2016-04-22 01:28:03 +0000
timestamp: 1461288483
uid: 468341
author: david-days
---

Well, if you look at the math that would support it, it actually becomes a bit more nuanced. (We can always adjust).

However, let's suppose that we want a fairly open-ended ranking system--we don't want to put an automatic "god-level" that has too much power, at least until we get some experience under our belt.

So an individual review would be 
    ReviewWeight = UserRep * ReviewPoints;

A total review weight would be averaged over the reviewer's reputation points:
    TotalReview = Sum(ReviewWeight) / Sum(UserReps)

A User with a reputation value of 100 gives a worse review than a reviewer with a reputation of 1000 (or vice versa), the higher-rep reviewer has more influence.

The UserRep value could be a sum of their own TotalReview results, Participation points (either automatically summed or "awarded" by PublicLab representatives), and even an adjustment value (either additive or multiplicative) to ameliorate or boost a particular user. 

(The last case could be used for someone trying to game the system with research "spam", while also allowing additional weight/credence to a user who comes in or develops street cred.)