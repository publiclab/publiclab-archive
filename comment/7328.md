---
cid: 7328
node: ![Calibrating DIY NIR cameras – part 1](../notes/nedhorning/10-21-2013/calibrating-diy-nir-cameras-part-1)
nid: 9509
created_at: 2013-10-23 14:39:59 +0000
timestamp: 1382539199
uid: 554
author: cfastie
---

Ned, 
This is a substantial advance, and an excellent explication of it. I like your statement of the problem – that what we have been doing with the Infragram so far is okay “if the intent is to detect relative changes in vegetation productivity or health across a **single image**.” You make a really important point that comparing NDVI results among images from different cameras is prone to errors and even comparing NDVI from images made with “the same camera in different lighting conditions or camera configurations” has limitations. It is really important that this approach might allow us “to generate similar NDVI images for each camera regardless of the white balance or camera settings.”  This will be crucial if we want to use inexpensive cameras with no capability to alter white balance settings.  Question: You mention that “camera configurations such as shutter speed, aperture, ASA speed, or white balance” can affect NDVI results. I can‘t think of a way that shutter speed or aperture by themselves could affect color balance, although bright and dark exposures of the same scene might have different relationships between channel values. I am also unsure how much ISO would affect NDVI, but it probably does change color balance a little. Is that what you were thinking? 

Have you been able to identify any materials that reflect in the intermediate range which is empty on the current graphs?  It would be good to fill the gap between 60 and 100 (blue) or 50 and 170 (red). I wonder if this would change your result that found that the blue channel was associated more strongly with 400nm than with 450nm which I thought was more representative of that channel. For the NIR channel, the cameras probably records between 750nm and 900nm, but the reflectance of the selected materials does not vary much across that range, so it doesn't matter which reference wavelength is used. 

To help us replicate your procedure, we might need some help when you get to this point: “The next step was to create NDVI images by applying the regression coefficients to calibrate the blue and red bands and then calculating NDVI.” Is the result of that step to change the values for each pixel in the blue and red channels of the infrablue photos so that e.g., in the graph “Ref400 vs Blue“ the “Blue band pixel values” (the x axis) for cardboard are changed from around 108 to around 95 (on average)? Maybe Jeff can suggest how this could be done using Infragrammar at the Infragram Sandbox after the regression equations are in hand. 

The NDVI from simple and multiple regressions do not differ much. How would you tell which is better?

NDVI based on reflectance calibration are higher than uncalibrated results by about 0.3, which seems to be a lot. Is 0.85 an expected result for NDVI of healthy grass? In other words, are the calibrated results reasonable?

The color table you used seems to assign red to values near 0 and also to values near 1. That made my head hurt a little.

I think this line of inquiry is headed toward a protocol in which a card with several colors of known reflectance (e.g., at 450nm and 800nm) is included in each Infragram photo taken (or at least the first photo of a series under the same conditions). That will be very geeky.
