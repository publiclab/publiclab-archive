---
node: Updated photo monitoring plugin to compare NDVI with DVI
author: cfastie
created_at: 2014-08-28 15:52:02 +0000
timestamp: 1409241122
nid: 10610
cid: 10133
uid: 554
---



[cfastie](../profile/cfastie) replying to: [Updated photo monitoring plugin to compare NDVI with DVI](../notes/nedhorning/06-24-2014/updated-photo-monitoring-plugin-to-compare-ndvi-with-dvi)

----
I don’t quite understand how this subtraction would work. When using a red filter, we expect the blue channel to record mostly near infrared light (NIR), and we expect the red channel to record lots of both red and NIR light. The subtraction idea is based on the concept that since we have a good measure of NIR light (blue channel) we can subtract that from the measure of red+NIR light (red channel) and approximate a measure of pure red light. 

That concept involves the assumption that red light and NIR light are being recorded in comparable ways. Does the blue channel record NIR light the same way the red channel records NIR light? Does the blue channel record NIR light the same way the red channel records red light? For example, if you have two equally bright LEDs, one pure red and one pure NIR, illuminating a perfectly reflective surface, and you take an Infragram photo of the surface, will the brightness value recorded in the red channel be twice that recorded in the blue channel?

I think this is not going to be true very often. The relative brightness of those two channels is going to be strongly influenced by the white balance setting on the camera. The standard white balance setting for red filtered infragram cameras strongly exaggerates the brightness of the blue channel. It does that so the brightness of healthy foliage recorded in the blue channel is several times greater than the brightness in the red channel.  This allows us to calculate some semblance of NDVI with the values in the photos straight from the camera.  I think this protocol ensures that subtracting the value in the blue channel (NIR) from the value in the red channel (red + NIR) will produce a negative number, not an approximation of the brightness of red.

If a very different white balance setting is used, it might be reasonable to do the subtraction, but it might not offer any benefit over the current protocol.

If photos are recorded in RAW image format, then no adjustment is done to the relative brightness of the channels. So if more light gets through to the red channel than the blue channel, the difference in brightness will be faithfully recorded.  In this situation, doing the subtraction could make sense.  Ned’s calibration protocols rely on RAW images.

In order for the subtraction to produce the desired result (an approximation of the brightness of just red light), we still have to assume that NIR is being recorded equivalently in both the red and blue channels. This requires that the red and blue Bayer filters transmit similar amounts of NIR light.  Every sensor is a little different in this respect, but generally more NIR seems to be recorded in the red channel versus the blue.  So unless you can quantify the difference in channel sensitivity to NIR, the subtraction may not be a very precise way to approximate red, even when RAW image data is recorded. 
.  
[![spectral-response-ccd.jpg](https://i.publiclab.org/system/images/photos/000/006/140/medium/spectral-response-ccd.jpg)](https://i.publiclab.org/system/images/photos/000/006/140/original/spectral-response-ccd.jpg)   
.  
Ned’s calibration protocol involves putting targets of known spectral reflectivity into the photos. This allows him to know how much NIR is getting into each channel.  Without this step, the subtraction may not get us any closer to the real value for red.

Chris
