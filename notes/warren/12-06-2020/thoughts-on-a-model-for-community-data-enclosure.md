---
title: "Thoughts on a model for community data enclosure"

tagnames: 'community, ethics, data, lat:41, blog-submission, study-design, lon:-71, zoom:6, citscichat'
author: warren
path: /notes/warren/12-06-2020/thoughts-on-a-model-for-community-data-enclosure.md
nid: 25177
uid: 1
cids: 27770,27771,28869
---

# Thoughts on a model for community data enclosure

by [warren](/profile/warren) | December 06, 2020 19:09

December 06, 2020 19:09 | Tags: [community](/tag/community), [ethics](/tag/ethics), [data](/tag/data), [lat:41](/tag/lat:41), [blog-submission](/tag/blog-submission), [study-design](/tag/study-design), [lon:-71](/tag/lon:-71), [zoom:6](/tag/zoom:6), [citscichat](/tag/citscichat)

----

I wrote a long-winded reply to @liz's nice tweet positing an RFP process that communities could run to solicit and evaluate potential helpers or harmers.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">A2 Issue a clear RFP to those who would help, so that problem holders may evaluate benefits &amp; harms of potential partnerships <a href="https://twitter.com/hashtag/CitSciChat?src=hash&amp;ref_src=twsrc%5Etfw">#CitSciChat</a> <a href="https://t.co/NupTCfj8fH">https://t.co/NupTCfj8fH</a></p>&mdash; jawnscapes &amp; jawnscaping (@lizbarry) <a href="https://twitter.com/lizbarry/status/1327353280960327680?ref_src=twsrc%5Etfw">November 13, 2020</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<!--

(https://twitter.com/lizbarry/status/1327353280960327680)

> A2 Issue a clear RFP to those who would help, so that problem holders may evaluate benefits & harms of potential partnerships #CitSciChat

-->

Just pasting [my response](https://twitter.com/jywarren/status/1335659385947820032) below because it was so long that it's probably easier to read in this format! Thanks!

****

Hi all, returning here after giving it a think!

This gets at a broader idea of restructuring power and perspective that disrupts the subject/researcher frame. Imagining an RFP issued by a community not only makes researchers the ones who must jump through hoops and do their homework, but it changes the structure of consent by asserting community agency. 

Often, health researchers, (or technologists, or even activists) rely on their own structures of ethical consent (like IRBs) to enter into partnerships. But although institutional review boards (IRB) are important and well-intentioned, they focus on a single moment of informed consent, and then operate within those bounds. 

The problem with this is that the benefits and harms of a project may evolve over time (and so may our understanding of them). In addition, the parties involved may not speak for the whole range of stakeholders who may be affected by the work. 

I think researchers can feel stuck because they lack the ethical tools or frameworks to approach this problem, or even think about it. 

Community data, or individual data, currently enters a “consented-to space” which is controlled by researchers bound by ethical standards and practices. These can be quite strict; limiting the use of data to only a particular study and requiring re-consent for additional direct work with the data (I say direct because of course people can cite the study in other studies, or do meta-studies). 

I think new models are required to address this, and to recognize the importance of ongoing relationships and ongoing trust-building for the lifetime of the data. In the WhereWeBreathe project I participated in at @PublicLab, we prototyped a means of locking researchers out of health datasets using an architecture of data management which granted access only to those electing to share their data.

No access to raw data would be allowed to researchers, who could only submit requests to visualize the data, and see the outcome of the visualization. Individuals could accept such requests and grant access, adding their data to the pool. 

While this brought up significant challenges to data analysis and study design, including questions of priming – where contributors (those called “subjects” in a typical study design) being able (or not) to see the effect of their inclusion on the visualizations generated, might impact the outcomes in many or most study designs. 

Contributors could also remove their data from the pool at any time, which would not affect already-generated visualizations but any future ones. And even more challenging was the control of privacy and anonymity such a system might or might not allow for participants. 

But importantly, it structured the data collection as primarily a process serving contributors themselves, rather than researchers. Contributors had full access to one another’s data, and could use the system to compile a “dossier” of their own data for evidential use, for example in court, or to present to journalists. Researchers would be forced to build trust with contributors in order to gain and retain access to the data. 

This system design surprised the researchers we were working with. At first they didn’t understand that we were proposing a system which would structurally exclude them from the data. But to their great credit, they thought on these issues and were supportive of the architecture, even going as far as to suggest ways that priming could be mitigated through alternative study designs. 

I was reminded of the ways in which AIDS researchers in the 90s were able (and willing) to adapt clinical trial design in response to the hard work of AIDS activists, including patients. However, this didn’t come without a fight – and although you can learn about this story in Alan Irwin’s 1995 book Citizen Science: A Study of People, Expertise, and Sustainable Development, and in Caren Cooper’s 2014 blog post (https://blog.scistarter.org/2014/07/coops-citizen-sci-scoop-hiv-aids-research/), the framing of “How could the lay public improve their research?” seems an institutionally centric way to understand what happened.

Of course it’s good that dialogue and collaboration emerged, but the problem statement wasn’t only that AIDS activists wanted to accelerate and improve institutional science, but that they were fighting for the recognition that science and health policy “as usual” was woefully insufficient, and that the mistakes of formal science and health experts were leading to immoral and unnecessary deaths. The goal wasn’t a noble attempt to “make science better” but a (perhaps even more noble) fight over the meaning of expertise and the negotiation of informed consent when many institutional experts wouldn’t even acknowledge the problems in their approach. 

Fundamentally, activists and patients weren’t considered part of the research process except as subjects – or troublemakers. And such attitudes persist – I remember how shaken I was to hear someone at a recent scientific meeting argue – angrily – that such activists bore responsibility for many subsequent deaths for having disrupted clinical trials. 

Just as in the AIDS crisis, environmental crises cannot be ethically – or successfully – fought without the centering of people and communities who directly face harms. And structural change will take imagination and care. The system we prototyped at @PublicLab was an attempt to remake such collaboration at a structural level, and had plenty of possible flaws, but critically, it imagined a different configuration, a different set of assumptions, about how ownership, consent, and the lifecycle of data, could work. 

(Regarding the title, I'm tempted to call this structural pattern "Community data enclosure" but that is probably too inflammatory as it pokes at the fissures between the ethics of open source/open access and the ethics of appropriation)