---
title: "CivilServant Community Research Summit, community, society and moderation systems"\ntagnames: 'collaboration, outreach, research, peer-production, moderation, newcomers, onboarding, welcoming, wikipedia'
author: warren
path: /notes/warren/01-27-2018/civilservant-community-research-summit-community-society-and-moderation-systems.md
nid: 15627
uid: 1

---

![](https://publiclab.org/public/system/images/photos/000/023/386/original/image.png)

# CivilServant Community Research Summit, community, society and moderation systems

by [warren](../profile/warren) | January 27, 2018 20:28

January 27, 2018 20:28 | Tags: [collaboration](../tag/collaboration), [outreach](../tag/outreach), [research](../tag/research), [peer-production](../tag/peer-production), [moderation](../tag/moderation), [newcomers](../tag/newcomers), [onboarding](../tag/onboarding), [welcoming](../tag/welcoming), [wikipedia](../tag/wikipedia)

----

I spent today at the [CivilServant](https://civilservant.io/) summit, where Nathan Matias and others invited many different presenters for the day around the topics of moderation and collaboration -- [CivilServant.io](http://CivilServant.io) is a platform for comparing and testing moderation systems -- and a discussion of tools for facilitating and moderating online discourse. The event was funded by the Knight Foundation, the MacArthur Foundation, and the Tow Center for Digital Journalism.

In opening remarks, Nathan mentioned a paper which I found pretty fascinating!

**The Rise and Decline of an Open Collaboration System: How Wikipedia's Reaction to Popularity Is Causing Its Decline**

by Aaron Halfaker, R. Stuart Geiger, Jonathan T. Morgan, John Riedl

[https://www-users.cs.umn.edu/~halfaker/publications/The\_Rise\_and\_Decline/](https://www-users.cs.umn.edu/~halfaker/publications/The_Rise_and_Decline/)

I was super interested to see this graph, where the authors argue that the moment when Wikipedia shifted from growth to slow decline in active editors happened **at the same time as the adoption of automated algorithmic editorial tools** which more eagerly rejected contributions:

![image description](https://publiclab.org/system/images/photos/000/023/362/large/decline.png "decline.png")

> Open collaboration systems like Wikipedia need to maintain a pool of volunteer contributors in order to remain relevant. Wikipedia was created through a tremendous number of contributions by millions of contributors. However, recent research has shown that the number of active contributors in Wikipedia has been declining steadily for years, and suggests that **a sharp decline in the retention of newcomers is the cause**. This paper presents data that show that several changes the Wikipedia community made to manage quality and consistency in the face of a massive growth in participation have ironically crippled the very growth they were designed to manage. Specifically, the restrictiveness of the encyclopedia's primary quality control mechanism and **the algorithmic tools used to reject contributions are implicated as key causes of decreased newcomer retention**. Further, the community's formal mechanisms for norm articulation are shown to have calcified against changes -- especially changes proposed by newer editors.

---------

### Discrimination and racism in algorithmic analysis

I also heard via Karrie Karahalios about her work on racial and other bias in algorithmic systems, including a [racist robotic beauty contest](https://www.theguardian.com/technology/2016/sep/08/artificial-intelligence-beauty-contest-doesnt-like-black-people), racist and discriminatory [automated "recidivism scoring"](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing), and other deeply disturbing stories of algorithmic misuse. She particularly pointed out this Obama-era report on **Big Data: A Report on Algorithmic Systems, Opportunity, and Civil Rights**:

[https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/2016\_0504\_data\_discrimination.pdf](https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/2016_0504_data_discrimination.pdf)

---------

![image description](https://publiclab.org/system/images/photos/000/023/387/large/Screenshot_2018-01-27_at_2.40.19_PM.png "Screenshot_2018-01-27_at_2.40.19_PM.png")

### Gobo

I was also interested in this tool Gobo, which lets you filter your own social media feed by different metrics -- instead of letting Twitter do it for you, for example. It gets at some of the non-neutrality of algorithmic filtering and the lack of agency of social media users in filtering on metrics that might be more socially or culturally relevant to you -- although it's not immediately clear how these metrics are evaluated: "politics", "seriousness", "rudeness", "gender", "brands", and "virality".

But watch out, it does require an IRB ethics "consent to be studied" since it's part of an academic experiment:

[http://gobo.social](http://gobo.social)

---------

### Posting rules increases participation

Not to bury the lede, but I was also struck by this study by CivilServant and the /r/science subReddit, which showed that:

#### Rule postings made newcomer comments 7.3 percentage points more likely to follow the rules, increasing newcomer participation by 38.1% on average, in a field experiment of 2,214 discussions on r/science.

[https://civilservant.io/moderation\_experiment\_r\_science\_rule\_posting.html](https://civilservant.io/moderation_experiment_r_science_rule_posting.html)![image description](https://publiclab.org/system/images/photos/000/023/388/medium/XHcfqbx.png "XHcfqbx.png")

> Sticking a rule comment to the top of discussion threads increased a newcomer's probability of posting a first comment within the rules, from a fitted chance of 75.2% to a fitted chance of 82.4% on average within r/science